@@ -1,460 +1,440 @@
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from datetime import datetime\n",
    "from math import ceil, floor\n",
    "from skimage.util import montage\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import Compose\n",
    "from typing import *\n",
    "import copy \n",
    "import cv2\n",
    "import glob\n",
    "import inspect\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import pickle\n",
    "import random \n",
    "import scipy\n",
    "import sklearn\n",
    "import socket\n",
    "import string\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import data_prep, dataset, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_prep.get_df_from_folder('/home/anuj/code/data/lfw_train')\n",
    "df_train, df_val = data_prep.split_train_val(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(idx     1356\n",
       " path    1356\n",
       " dtype: int64, idx     340\n",
       " path    340\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "outputs": [],
   "source": [
    "np.sum(df_train.groupby('label').count() > 1), np.sum(df_val.groupby('label').count() > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 327,846 total positive pairs 2,733 mini batches\n",
      "Training: 15,200 total positive pairs 127 mini batches\n"
     ]
    }
   ],
   "source": [
    "dataset_train, dataloader_train = dataset.get_dataloader(df_train, batch_size=5*24)\n",
    "dataset_val, dataloader_val = dataset.get_dataloader(df_val, batch_size=5*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some"
    "dataset_train, dataloader_train = dataset.get_dataloader(df_train, image_side=160, batch_size=5*24)\n",
    "dataset_val, dataloader_val = dataset.get_dataloader(df_val, image_side=160, batch_size=5*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, Optimizer, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import segnet\n",
    "from src import models\n",
    "from src.loss import ContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = segnet.SiameseNetworkLarge(256)\n",
    "model = models.SiameseNet(160)\n",
    "model = torch.nn.DataParallel(model, device_ids=[1]).cuda(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "outputs": [],
   "source": [
    "model.module.load_state_dict(torch.load('face-contrastive-2.04-7500.pt'))"
    "model.module.load_state_dict(torch.load('weights/face-siamese-crop.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_dist_vs_label(dataloader, n_iters=50):\n",
    "    all_labels, all_dists = [], []\n",
    "\n",
    "    for ix, batch in enumerate(dataloader):\n",
    "        if ix >= n_iters:\n",
    "            break\n",
    "        images1, images2, labels = dataset.flatten(batch) \n",
    "\n",
    "        with torch.no_grad():\n",
    "            feats1, feats2 = model(images1, images2)\n",
    "            dist = torch.nn.functional.pairwise_distance(feats1, feats2)\n",
    "\n",
    "        all_labels.extend(labels.data.cpu().numpy())\n",
    "        all_dists.extend(dist.data.cpu().numpy())\n",
    "\n",
    "    all_dists = np.array(all_dists)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "#     df_dist_label = pd.DataFrame([all_dists, all_labels], index=['dist', 'label']).T\n",
    "    return all_dists, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.7 s, sys: 33 s, total: 1min 31s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "outputs": [],
   "source": [
    "%%time\n",
    "all_dists_train, all_labels_train = get_df_dist_vs_label(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.5 s, sys: 32.5 s, total: 1min 30s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "outputs": [],
   "source": [
    "%%time\n",
    "all_dists_val, all_labels_val = get_df_dist_vs_label(dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshs = [0.1, 0.5, 0.8, 1, 1.2, 1.5, 2, 3]"
    "threshs = [0.1, 0.2, 0.3, 0.5, 0.8, 1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 [0.67609602 0.08090822]\n",
      "0.5 [0.9333438  0.92462044]\n",
      "0.8 [0.96024942 0.95898065]\n",
      "1 [0.96562656 0.96570668]\n",
      "1.2 [0.96620278 0.96719898]\n",
      "1.5 [0.95368485 0.95710101]\n",
      "2 [0.60005822 0.77716139]\n",
      "3 [0.22483544 0.69601787]\n"
     ]
    }
   ],
   "outputs": [],
   "source": [
    "for thresh in threshs:\n",
    "    preds = np.array(all_dists_train < thresh, dtype=np.int)\n",
    "    print(thresh, precision_recall_fscore_support(all_labels_train, preds)[2])"
    "    f1s = precision_recall_fscore_support(all_labels_train, preds)[2]\n",
    "    print(thresh, f1s, f1s.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 [0.70860653 0.30236176]\n",
      "0.5 [0.85651984 0.80726421]\n",
      "0.8 [0.88963495 0.8705062 ]\n",
      "1 [0.90359183 0.89495451]\n",
      "1.2 [0.91119468 0.90970968]\n",
      "1.5 [0.90288256 0.91116518]\n",
      "2 [0.63617487 0.78519598]\n",
      "3 [0.21466825 0.69446695]\n"
     ]
    }
   ],
   "outputs": [],
   "source": [
    "for thresh in threshs:\n",
    "    preds = np.array(all_dists_val < thresh, dtype=np.int)\n",
    "    print(thresh, precision_recall_fscore_support(all_labels_val, preds)[2])"
    "    f1s = precision_recall_fscore_support(all_labels_val, preds)[2]\n",
    "    print(thresh, f1s, f1s.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESH = 1.2"
    "THRESH = 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = data_prep.get_df_from_folder('/home/anuj/code/data/lfw_heldout/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 422 total positive pairs 4 mini batches\n"
     ]
    }
   ],
   "outputs": [],
   "source": [
    "dataset_test, dataloader_test = dataset.get_dataloader(df_test, batch_size=5*24)"
    "dataset_test, dataloader_test = dataset.get_dataloader(df_test, image_side=160, batch_size=5*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.07 s, sys: 1.24 s, total: 3.31 s\n",
      "Wall time: 4.42 s\n"
     ]
    }
   ],
   "outputs": [],
   "source": [
    "%%time\n",
    "all_dists_test, all_labels_test = get_df_dist_vs_label(dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2 (array([0.74429224, 0.7635468 ]), array([0.77251185, 0.73459716]), array([0.75813953, 0.74879227]), array([422, 422]))\n"
     ]
    }
   ],
   "outputs": [],
   "source": [
    "preds = np.array(all_dists_test < 1.5, dtype=np.int)\n",
    "preds = np.array(all_dists_test < THRESH, dtype=np.int)\n",
    "print(THRESH, precision_recall_fscore_support(all_labels_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import predict\n",
    "\n",
    "\n",
    "def show_images(ax, image_path1, image_path2, label):\n",
    "    im1 = cv2.imread(image_path1)\n",
    "    im2 = cv2.imread(image_path2)\n",
    "    im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)\n",
    "    im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image = np.hstack([im1, im2])\n",
    "    ax.imshow(image.astype(np.uint8))\n",
    "    ax.set_title(label)\n",
    "\n",
    "def visualize_preds(dataset, n=10, start=0, threshold=1.8):\n",
    "    plt.figure(figsize=(20, 50))\n",
    "    for ix in range(n):\n",
    "        idx1, idx2 = dataset[start+ix]['pairs'][ix%2]\n",
    "\n",
    "        i1 = str(dataset.df.loc[idx1]['path'])\n",
    "        i2 = str(dataset.df.loc[idx2]['path'])\n",
    "        # !python predict.py -img1 {i1} -img2 {i2}\n",
    "        dist, issame = predict.predict(i1, i2, model, transforms, 'cpu', threshold)\n",
    "        label = 'Dis-similarity: {:.2f}, Same person?: {}'.format(dist, bool(issame))\n",
    "\n",
    "        ax = plt.subplot(n, 2, ix+1)\n",
    "        show_images(ax, i1, i2, label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = predict.get_model('cpu', 'weights/face-siamese-crop.pt')\n",
    "transforms = preprocess.get_transforms_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_preds(dataset_train, n=10, start=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_preds(dataset_val, n=10, start=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_preds(dataset_test, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.models import segnet\n",
    "\n",
    "def fix_weights(path, out, device):\n",
    "    state_dict = torch.load(path, map_location={'cuda:2': device})\n",
    "\n",
    "    m = torch.nn.DataParallel(segnet.SiameseNetworkLarge(160))\n",
    "    m.load_state_dict(state_dict)\n",
    "    torch.save(m.module.state_dict(), out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
